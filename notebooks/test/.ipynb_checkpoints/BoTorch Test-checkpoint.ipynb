{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dtype = torch.double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.test_functions import Hartmann\n",
    "\n",
    "\n",
    "nega_hartmann6 = Hartmann(negate=True)\n",
    "\n",
    "\n",
    "def outcome_constraint(X):\n",
    "    return X.sum(dim=-1) - 3\n",
    "\n",
    "\n",
    "def weighted_obj(X):\n",
    "    return neg_hartmann6(X) * (outcome_constraint(X) <= 0).type_as(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models import FixedNoiseGP, ModelListGP\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "\n",
    "\n",
    "NOISE_SE = 0.5\n",
    "y_train_var = torch.tensor(NOISE_SE ** 2, device=device, dtype=dtype)\n",
    "\n",
    "\n",
    "def generate_initial_data(n=10):\n",
    "    x_train = torch.rand(n, 6, device=device, dtype=dtype)\n",
    "    \n",
    "    exact_obj = neg_hartmann6(x_train).unsqueeze(-1)\n",
    "    exact_con = outcome_constraint(x_train).unsqueeze(-1)\n",
    "    \n",
    "    train_obj = exact_obj + NOISE_SE * torch.randn_like(exact_obj)\n",
    "    train_con = exact_con + NOISE_SE * torch.randn_like(train_con)\n",
    "    \n",
    "    best_observed = weighted_obj(x_train).max().item()\n",
    "    \n",
    "    return x_train, train_obj, train_con, best_observed\n",
    "\n",
    "\n",
    "def initialize_model(x_train, train_obj, train_con, state_dict=None):\n",
    "    # Define model\n",
    "    model_obj = FixedNoiseGP(x_train, train_obj, y_train_var.expand_as(train_obj)).to(x_train)\n",
    "    model_con = FixedNosieGP(x_train, train_con, y_train_var.expand_as(train_con)).to(x_train)\n",
    "    \n",
    "    # Combine into a multi-output GP model\n",
    "    model = ModelListGP(model_obj, model_con)\n",
    "    mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "    \n",
    "    # Load state dict if passed\n",
    "    if state_dict is not None:\n",
    "        model.load_state_dict(state_dict)\n",
    "    \n",
    "    return mll, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition.objective import ConstrainedMCObjective\n",
    "\n",
    "\n",
    "def obj_callable(Z):\n",
    "    return Z[..., 0]\n",
    "\n",
    "\n",
    "def constraint_callable(Z):\n",
    "    return Z[..., 1]\n",
    "\n",
    "\n",
    "# Define a feasibility-weighted objective for optimization\n",
    "constrained_obj = ConstrainedMCObjective(\n",
    "    objective=obj_callable,\n",
    "    constraints=[constraint_callable]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "\n",
    "BATCH_SIZE = 3\n",
    "bounds = torch.tensor([[0.0] * 6, [1.0] * 6], device=device, dtype=dtype)\n",
    "\n",
    "\n",
    "def optimize_acqf_and_get_observation(acq_fn):\n",
    "    '''\n",
    "    Optimizes the acquisition function and returns a new candidate with a noisy observation.\n",
    "    '''\n",
    "    # Optimize\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=acq_fn,\n",
    "        bounds=bounds,\n",
    "        q=BATCH_SIZE,\n",
    "        num_starts=10,\n",
    "        raw_samples=500,  # used for initialization heuristic\n",
    "        options={\n",
    "            'batch_limit': 5,\n",
    "            'max_iter': 200\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Observe new values\n",
    "    new_x = candidates.detach()\n",
    "    \n",
    "    exact_obj = neg_hartmann6(new_x).unsqueeze(-1)\n",
    "    exact_con = outcome_constraint(new_x).unsqueeze(-1)\n",
    "    \n",
    "    new_obj = exact_obj + NOISE_SE * torch.randn_like(exact_obj)\n",
    "    new_con = exact_con + NOISE_SE * torch.randn_like(exact_con)\n",
    "    \n",
    "    return new_x, new_obj, new_con\n",
    "\n",
    "\n",
    "def update_random_observations(best_random):\n",
    "    '''\n",
    "    Simulates a random policy by taking the current list of best observations,\n",
    "    drawing a new random point, observing its value, and updating the list.\n",
    "    '''\n",
    "    rand_x = torch.rand(BATCH_SIZE, 6)\n",
    "    next_random_best = weighted_obj(rand_x).max().item()\n",
    "    best_random.append(max(best_random[-1], next_random_best))\n",
    "    \n",
    "    return best_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch import fit_gpytorch_model\n",
    "from botorch.acquisition.monto_carlo import qExpectedImprovement, qNoisyExpectedImprovement\n",
    "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "\n",
    "N_TRIALS = 3\n",
    "N_BATCH = 20\n",
    "MC_SAMPLES = 500\n",
    "\n",
    "verbose = True\n",
    "\n",
    "\n",
    "best_observed_all_ei, best_observed_all_nei, best_random_all = [], [], []\n",
    "\n",
    "# Average over multiple trials\n",
    "for trial in range(1, N_TRIALS + 1):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Fit the model\n",
    "    fit_gpytorch_model(mll_ei)\n",
    "    fit_gpytorch_model(mll_nei)\n",
    "    \n",
    "    # Define the qEI and qNEI acquisition moddules using a QMC sampler\n",
    "    qmc_sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)\n",
    "    \n",
    "    # For best_f, use the best observed noisy values as an approximation\n",
    "    qEI = qExpectedImprovement(\n",
    "        model=model_ei,\n",
    "        best_f=(train_obj_ei * (train_con_ei <= 0).to(train_obj_ei)).max(),\n",
    "        sampler=pmc_sampler,\n",
    "        objective=constrained_obj\n",
    "    )\n",
    "    \n",
    "    qNEI = qNoisyExpectedImprovement(\n",
    "        model=model_nei,\n",
    "        X_baseline=x_train_nei,\n",
    "        sampler=qmc_sampler,\n",
    "        objective=constrained_obj\n",
    "    )\n",
    "    \n",
    "    # Optimize and get new observations\n",
    "    new_x_ei, new_obj_ei, new_con_ei = optimize_acqf_and_get_observation(qEI)\n",
    "    new_x_nei, new_obj_nei, new_con_nei = optimize_acqf_and_get_observation(qNEI)\n",
    "    \n",
    "    # Update training points\n",
    "    x_train_ei = torch.cat([x_train_ei, new_x_ei])\n",
    "    train_obj_ei = torch.cat([train_obj_ei, new_obj_ei])\n",
    "    train_con_ei = torch.cat([train_con_ei, new_con_ei])\n",
    "    \n",
    "    x_train_nei = torch.cat([x_train_nei, new_x_nei])\n",
    "    train_obj_nei = torch.cat([train_obj_nei, new_obj_nei])\n",
    "    train_con_nei = torch.cat([train_con_nei, new_con_nei])\n",
    "    \n",
    "    # Update progress\n",
    "    best_random = update_random_observations(best_random)\n",
    "    best_value_ei = weighted_obj(x_train_ei).max().item()\n",
    "    best_value_nei = weighted_obj(x_train_nei).max().item()\n",
    "    best_observed_ei.append(best_value_ei)\n",
    "    best_observed_nei.append(best_value_nei)\n",
    "    \n",
    "    # Reinitialize the models\n",
    "    mll_ei, model_ei = initialize_model(\n",
    "        x_train_ei,\n",
    "        train_obj_ei,\n",
    "        train_con_ei,\n",
    "        model_ei.state_dict()\n",
    "    )\n",
    "    mll_nei, model_nei = initialize_model(\n",
    "        x_train_nei,\n",
    "        train_obj_nei,\n",
    "        train_con_nei,\n",
    "        model_nei.state_dict()\n",
    "    )\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Batch {iteration}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
